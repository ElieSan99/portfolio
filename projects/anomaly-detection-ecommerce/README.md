# D√©tection d'Anomalies E-commerce ‚Äî Big Data & Time Series (Kering)

> [!NOTE]
> **Projet de Stage de Fin d'√âtudes (Datafab pour Kering)**  
> *Le code source de ce projet est confidentiel et n'est pas publi√© dans ce portfolio. Ce document d√©taille la m√©thodologie, les technologies et les r√©sultats obtenus.*

## üéØ Contexte m√©tier
Ce projet a √©t√© r√©alis√© pour le groupe **Kering** (Luxe) dans le cadre d'un stage chez **Datafab**. L'enjeu √©tait de surveiller les flux transactionnels des commandes des clients afin de d√©tecter des anomalies (pics de ventes inhabituels, baisses injustifi√©es) en temps quasi-r√©el.

## ‚ùì Probl√®me √† r√©soudre
D√©tecter des anomalies dans des s√©ries temporelles √† haute fr√©quence et fort volume, sans avoir de donn√©es √©tiquet√©es (approche **non supervis√©e**). Le syst√®me devait √™tre capable de :
- G√©rer des volumes de donn√©es massifs.
- S'adapter √† la saisonnalit√© complexe du luxe (ventes priv√©es, lancements).
- R√©duire le nombre de fausses alertes pour les √©quipes op√©rationnelles.

## üèóÔ∏è Architecture & Stack Technique
Le projet repose sur une infrastructure Cloud robuste pour traiter la donn√©e √† l'√©chelle :
- **Pr√©-traitement & Analyse :** **Apache Zeppelin (PySpark)** pour le nettoyage, l'agr√©gation de millions de lignes et l'exploration des donn√©es.
- **Mod√©lisation :** Facebook **Prophet** (pour la baseline de saisonnalit√©) et **LSTM** (Deep Learning) pour capturer les d√©pendances temporelles complexes.
- **Orchestration & D√©ploiement :** **Vertex AI** (GCP) pour le suivi des mod√®les et la mise en production.

## ‚öôÔ∏è Approche technique : "Predictive Anomaly Detection"
L'approche retenue est une d√©tection bas√©e sur l'erreur de pr√©diction :
1.  **Mod√©lisation de la normale :** Entra√Ænement de mod√®les (Prophet/LSTM) pour pr√©dire les valeurs futures attendues.
2.  **Calcul de l'√©cart :** Comparaison de la valeur r√©elle avec l'intervalle de confiance pr√©dit.
3.  **Score d'anomalie :** Utilisation d'un seuil statistique (bas√© sur la distribution de l'erreur) pour d√©clencher une alerte si l'√©cart est trop important.

## üöÄ D√©ploiement & MLOps
- Mise en place de pipelines Vertex AI pour l'automatisation du r√©-entra√Ænement.
- Monitoring des performances du mod√®le pour √©viter la d√©rive (drift).

## üìà Impact & R√©sultats
- R√©cup√©ration et traitement de donn√©es massives.
- R√©duction significative du temps de d√©tection des incidents techniques sur le tunnel de vente.


## üîß Comp√©tences cl√©s d√©montr√©es
- **Big Data & Notebooks :** **PySpark**, **Apache Zeppelin** (Notebooks distribu√©s).
- **Advanced Analytics :** Deep Learning pour s√©ries temporelles (LSTM), Prophet.
- **Cloud/MLOps :** Ma√Ætrise de l'√©cosyst√®me Google Cloud (Vertex AI).
